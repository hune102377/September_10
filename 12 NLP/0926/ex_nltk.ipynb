{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent='Wiki is in Ward is original description: The simplest online database that could possibly work.\\\n",
    "Wiki is a piece of server software that allows users to freely create and edit Web page content using any Web browser. Wiki supports hyperlinks and has a simple text syntax for creating new pages and crosslinks between internal pages on the fly.\\\n",
    "Wiki is unusual among group communication mechanisms in that it allows the organization of contributions to be edited in addition to the content itself.Like many simple concepts, \"open editing\" has some profound and subtle effects on Wiki usage. Allowing everyday users to create and edit any page in a Web site is exciting in that it encourages democratic use of the Web and promotes content composition by nontechnical users.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiki is in Ward is original description: The simplest online database that could possibly work.Wiki is a piece of server software that allows users to freely create and edit Web page content using any Web browser. Wiki supports hyperlinks and has a simple text syntax for creating new pages and crosslinks between internal pages on the fly.Wiki is unusual among group communication mechanisms in that it allows the organization of contributions to be edited in addition to the content itself.Like many simple concepts, \"open editing\" has some profound and subtle effects on Wiki usage. Allowing everyday users to create and edit any page in a Web site is exciting in that it encourages democratic use of the Web and promotes content composition by nontechnical users.\n"
     ]
    }
   ],
   "source": [
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대소문자 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2692891333.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [14]\u001b[1;36m\u001b[0m\n\u001b[1;33m    대소문자 통일\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentToken = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wiki', 'is', 'in', 'Ward', 'is', 'original', 'description', ':', 'The', 'simplest', 'online', 'database', 'that', 'could', 'possibly', 'work.Wiki', 'is', 'a', 'piece', 'of', 'server', 'software', 'that', 'allows', 'users', 'to', 'freely', 'create', 'and', 'edit', 'Web', 'page', 'content', 'using', 'any', 'Web', 'browser', '.', 'Wiki', 'supports', 'hyperlinks', 'and', 'has', 'a', 'simple', 'text', 'syntax', 'for', 'creating', 'new', 'pages', 'and', 'crosslinks', 'between', 'internal', 'pages', 'on', 'the', 'fly.Wiki', 'is', 'unusual', 'among', 'group', 'communication', 'mechanisms', 'in', 'that', 'it', 'allows', 'the', 'organization', 'of', 'contributions', 'to', 'be', 'edited', 'in', 'addition', 'to', 'the', 'content', 'itself.Like', 'many', 'simple', 'concepts', ',', '``', 'open', 'editing', \"''\", 'has', 'some', 'profound', 'and', 'subtle', 'effects', 'on', 'Wiki', 'usage', '.', 'Allowing', 'everyday', 'users', 'to', 'create', 'and', 'edit', 'any', 'page', 'in', 'a', 'Web', 'site', 'is', 'exciting', 'in', 'that', 'it', 'encourages', 'democratic', 'use', 'of', 'the', 'Web', 'and', 'promotes', 'content', 'composition', 'by', 'nontechnical', 'users', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sentToken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정제화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 전 : ['Wiki', 'is', 'in', 'Ward', 'is', 'original', 'description', ':', 'The', 'simplest', 'online', 'database', 'that', 'could', 'possibly', 'work.Wiki', 'is', 'a', 'piece', 'of', 'server', 'software', 'that', 'allows', 'users', 'to', 'freely', 'create', 'and', 'edit', 'Web', 'page', 'content', 'using', 'any', 'Web', 'browser', '.', 'Wiki', 'supports', 'hyperlinks', 'and', 'has', 'a', 'simple', 'text', 'syntax', 'for', 'creating', 'new', 'pages', 'and', 'crosslinks', 'between', 'internal', 'pages', 'on', 'the', 'fly.Wiki', 'is', 'unusual', 'among', 'group', 'communication', 'mechanisms', 'in', 'that', 'it', 'allows', 'the', 'organization', 'of', 'contributions', 'to', 'be', 'edited', 'in', 'addition', 'to', 'the', 'content', 'itself.Like', 'many', 'simple', 'concepts', ',', '``', 'open', 'editing', \"''\", 'has', 'some', 'profound', 'and', 'subtle', 'effects', 'on', 'Wiki', 'usage', '.', 'Allowing', 'everyday', 'users', 'to', 'create', 'and', 'edit', 'any', 'page', 'in', 'a', 'Web', 'site', 'is', 'exciting', 'in', 'that', 'it', 'encourages', 'democratic', 'use', 'of', 'the', 'Web', 'and', 'promotes', 'content', 'composition', 'by', 'nontechnical', 'users', '.']\n",
      "불용어 제거 후 : ['Wiki', 'Ward', 'original', 'description', ':', 'The', 'simplest', 'online', 'database', 'could', 'possibly', 'work.Wiki', 'piece', 'server', 'software', 'allows', 'users', 'freely', 'create', 'edit', 'Web', 'page', 'content', 'using', 'Web', 'browser', '.', 'Wiki', 'supports', 'hyperlinks', 'simple', 'text', 'syntax', 'creating', 'new', 'pages', 'crosslinks', 'internal', 'pages', 'fly.Wiki', 'unusual', 'among', 'group', 'communication', 'mechanisms', 'allows', 'organization', 'contributions', 'edited', 'addition', 'content', 'itself.Like', 'many', 'simple', 'concepts', ',', '``', 'open', 'editing', \"''\", 'profound', 'subtle', 'effects', 'Wiki', 'usage', '.', 'Allowing', 'everyday', 'users', 'create', 'edit', 'page', 'Web', 'site', 'exciting', 'encourages', 'democratic', 'use', 'Web', 'promotes', 'content', 'composition', 'nontechnical', 'users', '.']\n",
      "불용어 제거 전 : 132\n",
      "불용어 제거 후 : 85\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "result = []\n",
    "for word in sentToken: \n",
    "    if word not in stop_words: \n",
    "        result.append(word) \n",
    "\n",
    "print('불용어 제거 전 :',sentToken) \n",
    "print('불용어 제거 후 :',result)\n",
    "print('불용어 제거 전 :', len(sentToken))\n",
    "print('불용어 제거 후 :',len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LJH\\Desktop\\File\\Study\\12 NLP\\0926\\ex_nltk.ipynb 셀 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LJH/Desktop/File/Study/12%20NLP/0926/ex_nltk.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ohe \u001b[39m=\u001b[39m CountVectorizer()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LJH/Desktop/File/Study/12%20NLP/0926/ex_nltk.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ret \u001b[39m=\u001b[39m ohe\u001b[39m.\u001b[39;49mtransform(result)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LJH/Desktop/File/Study/12%20NLP/0926/ex_nltk.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(ret)\n",
      "File \u001b[1;32mc:\\Users\\LJH\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1376\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(raw_documents, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1373\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1374\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIterable over raw text documents expected, string object received.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1375\u001b[0m     )\n\u001b[1;32m-> 1376\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_vocabulary()\n\u001b[0;32m   1378\u001b[0m \u001b[39m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m _, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_count_vocab(raw_documents, fixed_vocab\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\LJH\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:498\u001b[0m, in \u001b[0;36m_VectorizerMixin._check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_vocabulary()\n\u001b[0;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfixed_vocabulary_:\n\u001b[1;32m--> 498\u001b[0m         \u001b[39mraise\u001b[39;00m NotFittedError(\u001b[39m\"\u001b[39m\u001b[39mVocabulary not fitted or provided\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    500\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocabulary_) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mVocabulary is empty\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "ohe = CountVectorizer()\n",
    "ret = ohe.transform(result)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "399b942a90945adf822711c817a2148b24a3a269b52160aecaa333816877df5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
